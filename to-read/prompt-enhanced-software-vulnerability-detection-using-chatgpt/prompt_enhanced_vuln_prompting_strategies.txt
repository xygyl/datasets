Prompting Strategies in Prompt-Enhanced Software Vulnerability Detection Using ChatGPT

Location: Section 4.1 – Basic Prompting 
1. Basic Prompt (Pb):
   Is the following program buggy? Please answer Yes or No. [CODE]

2. Role-Based Basic Prompt (Pr-b):
   I want you to act as a vulnerability detection system.
   My first request is “Is the following program buggy?” Please answer Yes or No. [CODE]

3. Reverse-Question Role-Based Prompt (Pr-r-b):
   I want you to act as a vulnerability detection system.
   My first request is “Is the following program correct?” Please answer Yes or No. [CODE]

Location: Section 4.2.2 – Prompts with Auxiliary Information 
4. Data Flow Augmented Prompt (Pr-b-d):
   I want you to act as a vulnerability detection system.
   I will provide you with the original program and the data flow information, and you will act upon them.
   Is the following program buggy? [CODE].
   [DF description]

5. API Call Augmented Prompt (Pr-a-b):
   I want you to act as a vulnerability detection system.
   I will provide you with the original program and the API call sequence, and you will act upon them.
   [API description].
   Is the following program buggy? [CODE]

6. API Description Template:
   The program first calls a1, then calls a2, ···, then calls ai, ···, and finally calls an.

7. Data Flow Description Template:
   The data value of the variable vi at the pi-th token comes from/is computed by the variable vj at the pj-th token.

Location: Section 4.3 – Chain-of-Thought Prompting 
8. Code Intent Description Prompt (P(chain)1):
   Please describe the intent of the given code. [CODE]

9. Vulnerability Detection Prompt (P(chain)2,r-b):
   I want you to act as a vulnerability detection system.
   Is the above program buggy? Please answer Yes or No.

10. Vulnerability Detection with Auxiliary Info (P(chain)2,aux):
    I want you to act as a vulnerability detection system.
    Is the above code buggy? Only answer Yes or No.
    Here is its API call sequence/data flow information that you may use:
    [API description]/[DF description]

Results of Prompting Strategies:

Basic Prompting (RQ1):
- The Basic Prompt (Pb) achieved an overall accuracy of 69.1% on the Java dataset and 42.9% on the C/C++ dataset, outperforming the CFGNN (43.7% Java, 43.3% C/C++) and Bugram baselines.
- Adding a role (Pr-b) improved accuracy to 72.5% (Java) and 52.2% (C/C++), while the reverse-question variant (Pr-r-b) yielded 59.7% (Java) and 47.6% (C/C++).

Auxiliary Information (RQ2):
- Integrating API call sequences (Pr-a-b) boosted accuracy to 74.7% on Java and 51.4% on C/C++.
- Incorporating data-flow information (Pr-b-d) resulted in 66.9% (Java) and 52.5% (C/C++).
- Combining both API and data-flow info (Pr-a-b-d) had mixed effects: 61.5% (Java) and 50.0% (C/C++).

Chain-of-Thought Prompting (RQ3):
- The two-step CoT prompt without extra info (P(chain)2,r-b) achieved 70.1% accuracy on Java and 74.1% on C/C++.
- Including API or data-flow in the CoT step (P(chain)2,r-a-b, P(chain)2,r-b-d, P(chain)2,r-a-b-d) lowered Java performance to between 65.4% and 69.5% but improved C/C++ performance to between 69.7% and 71.4%.

Position Effects (RQ4):
- Optimal positioning was to place API descriptions before the code and data-flow descriptions after the code for role-based prompts, maximizing overall accuracy.

Vulnerability-Type Performance (RQ5):
- Under the Pr-a-b prompt, ChatGPT achieved 100% accuracy on 7 of 50 CWE types in Java, and over 50% accuracy on 82% of types.
- It struggled with context-insensitive cases like suspicious comments and missing salt, indicating areas needing additional domain knowledge.
