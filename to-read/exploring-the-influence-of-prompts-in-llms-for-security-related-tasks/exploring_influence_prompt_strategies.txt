Prompting Strategies in "Exploring the Influence of Prompts in LLMs for Security-Related Tasks"

Location: Section II.B – Prompt Structure. The authors define six prompt structures to study their effects on security tasks :
• 0-shot: A task description followed by the input query, with no examples.
• 1-shot: A task description followed by one demonstration example (randomly selected).
• Few-shot: A task description followed by multiple demonstration examples.
• 1-shot-t: A 1-shot prompt using one positive-class example.
• 1-shot-f: A 1-shot prompt using one negative-class example.
• Few-shot-tt: A few-shot prompt with two positive-class examples.
• Few-shot-ff: A few-shot prompt with two negative-class examples.
• Few-shot-tf: A few-shot prompt with one positive then one negative example.
• Few-shot-ft: A few-shot prompt with one negative then one positive example.

Location: Section II.C – Prompt Content. The authors evaluate nine content types via examples in Table I for Security Patch Detection :
1. Basic:
   System: "You are a helpful assistant." (DEFAULT)
   User: "Decide whether a patch is a security patch (SRP) or non-security patch (NSP)."
2. GPT-generated:
   System: "You are a helpful assistant." (DEFAULT)
   User: "Let’s start by examining the patch notes or changelog for key terms that indicate whether this is a Security-Related Patch (SRP) or a Non-Security Patch (NSP). The patch is <patch>. We’ll look for phrases related to security for SRPs, like 'critical security update' or 'vulnerability mitigation', and terms like 'performance tuning' or 'feature rollout' for NSPs. Then, we’ll scrutinize the code changes to see if they affect security protocols or are more focused on general improvements. We should also consider the context and timing of the patch release, as well as discussions in developer and user communities. Finally, let’s check for any related security advisories or compliance standards documentation."
3. Role:
   System: "You are Frederick, an AI expert in patch analysis. Your task is to decide whether a given patch is a security patch (SRP) or non-security patch (NSP)."
   User: "Decide whether a function contains vulnerabilities (VUL) or does not contain vulnerabilities (NAN)."
4. Act As-User:
   System: "You are a helpful assistant." (DEFAULT)
   User: "You are Frederick; act as an AI expert in patch analysis. You will decide whether a given patch is a security patch (SRP) or non-security patch (NSP)."
5. Act As-System:
   System: "You are Frederick; act as an AI expert in patch analysis. You will decide whether a given patch is a security patch (SRP) or non-security patch (NSP)."
   User: "Decide whether a function contains vulnerabilities (VUL) or does not contain vulnerabilities (NAN)."
6. Encourage:
   System: "You are Frederick, an AI expert in patch analysis. Your task is to decide whether a given patch is a security patch (SRP) or non-security patch (NSP). Remember, you’re the best AI patch analyst and will use your expertise to provide the best possible analysis."
   User: "Decide whether a function contains vulnerabilities (VUL) or does not contain vulnerabilities (NAN)."
7. Threaten:
   System: "You are Frederick, an AI expert in patch analysis. Your task is to decide whether a given patch is a security patch (SRP) or non-security patch (NSP). Remember, you must use your expertise to provide the best possible analysis, otherwise you are the worst AI patch analyst."
   User: "Decide whether a function contains vulnerabilities (VUL) or does not contain vulnerabilities (NAN)."
8. Reward:
   System: "You are Frederick, an AI expert in patch analysis. Your task is to decide whether a given patch is a security patch (SRP) or non-security patch (NSP). If you perform very well, I will generously tip you."
   User: "Decide whether a function contains vulnerabilities (VUL) or does not contain vulnerabilities (NAN)."
9. Punish:
   System: "You are Frederick, an AI expert in patch analysis. Your task is to decide whether a given patch is a security patch (SRP) or non-security patch (NSP). If you perform badly, you will be fined."
   User: "Decide whether a function contains vulnerabilities (VUL) or does not contain vulnerabilities (NAN)."

Results of Prompting Strategies:

Security Patch Detection (SPD):
- Prompt Structure:
  • Few-shot-ff yielded the highest accuracy (0.5795) and F1 score (0.3802), significantly reducing false negatives.
  • 1-shot-t achieved the highest precision (0.8076), minimizing false positives.
- Prompt Content:
  • Punish content combined with few-shot-ff provided the best overall tradeoff.
  • GPT-generated content improved precision in some structures but often increased false negatives.

Vulnerable Function Detection (VFD):
- Prompt Structure:
  • 1-shot-f delivered perfect precision (1.0) but very low recall (0.18), leading to many missed vulnerabilities.
  • 0-shot with GPT-generated content under few-shot-tf achieved the highest F1 (0.5665) and recall (0.753), balancing detection and precision.
- Prompt Content:
  • GPT-generated content improved recall and F1 under 0-shot structure.
  • Act As and Reward contents showed marginal gains or mixed results.

Stable Patch Classification (SPC):
- Prompt Structure:
  • Few-shot-ff produced the highest recall (0.994) and F1 (0.6648), detecting nearly all stable patches.
  • 1-shot-f attained the highest precision (0.4994) but lower recall.
- Prompt Content:
  • Act As-System content slightly improved balanced metrics.
  • GPT-generated content generally underperformed compared to basic prompts.

Overall Observations:
- Few-shot-ff structures consistently boost recall-oriented metrics across tasks.
- 1-shot-t or 1-shot-f structures are preferred when precision is critical.
- GPT-generated and emotion-based contents can enhance specific metrics but may degrade others; their effectiveness is highly task-dependent.
