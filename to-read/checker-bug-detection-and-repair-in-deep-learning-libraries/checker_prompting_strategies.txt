Prompt Engineering Strategies in TensorGuard (Checker-Bug-Detection-and-Repair-in-Deep-Learning-Libraries.pdf)

Location: Section III.A.2 – Prompt Engineering for Different Agents. 

1. Checker Bug Detection Agent
   a. Chain of Thought (CoT) Prompt (Table V):
      Prompt:
      “You are an AI trained to detect bugs in a deep-learning library based on commit messages and code changes. Your task is to determine whether a given commit introduces a bug or not. Follow the steps below to reason through the problem and arrive at a conclusion.
      1. Understand the commit message: Analyze the commit message to understand the context and purpose of the code change.
      2. Review the code change: Examine the deleted and added lines of code to identify the modifications made.
      3. Identify potential issues: Look for any missing, improper, or insufficient checkers within the code change. Checkers may include error handling, input validation, boundary checks, or other safety mechanisms.
      4. Analyze the impact: Consider the impact of the identified issues on the functionality and reliability of the deep learning libraries.
      5. Make a decision: Based on the above analysis, decide whether the commit introduces a bug or not.
      6. Output the conclusion: Generate a clear output of “YES” if the commit introduces a bug, or “NO” if it does not.
      Output field: {Decision} 

   b. Zero-Shot Prompt (Table VI):
      Prompt:
      “You are an AI trained to detect bugs in a deep-learning library based on commit messages and code changes. Your task is to determine whether a given commit introduces a bug or not. Follow the steps below to reason through the problem and arrive at a conclusion.
      Commit message: {commit message}
      Code change: {code removed}{code added}
      Output field: {Decision}” 

   c. Few-Shot Prompt (Table VII):
      Prompt:
      “You are an AI trained to detect bugs in a deep-learning library based on commit messages and code changes. Your task is to determine whether a given commit introduces a bug or not.

      Example Checker Bug One:
      Commit message: {commit message}
      Code change: {code removed}{code added}

      Example Checker Bug Two:
      Commit message: {commit message}
      Code change: {code removed}{code added}

      Task:
      Commit message: {commit message}
      Code change: {code removed}{code added}
      Output field: {Decision}” 

2. Root Cause Analysis Agent (Table VIII)
   Location: Section III.A.2 
   Prompt:
   “Please describe the root cause of the bug based on the following commit message:
   {commit message}
   Output field: {Root causes}” 

3. Patch Generation Agent (Table IX)
   Location: Section III.A.2 
   Prompt:
   “You are given a bug explanation and an external context for fixing a checker bug. Please think step by step and generate a patch to fix the bug in the code snippet. Please neglect any issues related to the indentation in the code snippet. If you think the given pattern can be applied, generate the patch.

   Example One: {code removed} {code added}
   Example Two: {code removed} {code added}

   Bug explanation: {bug explanation}
   Retrieved context: {retrieved knowledge}
   Code snippet: {code snippet}
   Output field: {Think steps}{Patch}” 

Results of Prompting Strategies:

Detection Effectiveness:
- Chain-of-Thought Prompting:
  • PyTorch: Precision 50.75%, Recall 100.00%, F1 67.33%
  • TensorFlow: Precision 30.05%, Recall 89.03%, F1 44.93%
  • Average: Precision 40.40%, Recall 94.51%, F1 56.12%
  (high recall, many false positives)

- Zero-Shot Prompting:
  • PyTorch: Precision 66.47%, Recall 79.34%, F1 72.33%
  • TensorFlow: Precision 57.46%, Recall 63.22%, F1 60.20%
  • Average: Precision 61.96%, Recall 71.28%, F1 66.26%
  (balanced precision and recall)

- Few-Shot Prompting:
  • PyTorch: Precision 69.30%, Recall 37.04%, F1 48.74%
  • TensorFlow: Precision 55.60%, Recall 50.96%, F1 53.17%
  • Average: Precision 62.45%, Recall 44.00%, F1 50.95%
  (high precision, lower recall)

Patch Generation:
- TensorGuard: Generated 90 patches, 10 correct → Accuracy 11.1%
- AutoCodeRover (baseline): Generated 32 patches, 3 correct → Accuracy 9.3%

New Bug Detection (JAX library):
- Evaluated 493 checker-related changes:
  • Detected: 118 potential bugs
  • True bugs: 64 confirmed
  • Correct fixes generated: 4
