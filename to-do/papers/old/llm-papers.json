[
  {
    "title": "Advancing Bug Detection in Fastjson2 with LLM-Driven Unit Test Generation",
    "year": 2024,
    "venue": "arXiv preprint",
    "strategies": [
      "Example-Driven Mutation Prompts: Seeded with historical bug-triggering tests and JSON-specific mutation rules (e.g., 'add duplicate keys', 'nest objects deeply').",
      "Differential-Test Oracle Prompt: Secondary prompt to classify failing tests as true bugs or false positives."
    ]
  },
  {
    "title": "Checker Bug Detection and Repair in Deep Learning Libraries (TensorGuard)",
    "year": 2024,
    "venue": "arXiv preprint",
    "strategies": [
      "Zero-Shot / Few-Shot / Chain-of-Thought Variants: Evaluated under zero-shot, few-shot (3 examples), and chain-of-thought ('explain step-by-step why this is or isn't a bug').",
      "Role Prompt + Retrieval-Augmented Context: 'You are a code analyst' role prompt with injected relevant API documentation."
    ]
  },
  {
    "title": "Comparison of Static Application Security Testing Tools and LLMs for Repo-Level Vulnerability Detection",
    "year": 2024,
    "venue": "arXiv preprint",
    "strategies": [
      "Zero-Shot Prompting: 'Analyze this repository for vulnerabilities.'",
      "Chain-of-Thought Prompting: Appending 'Let's think step by step' for reasoning.",
      "Few-Shot Prompting: Including two labeled examples to calibrate model output."
    ]
  },
  {
    "title": "Detecting Code Smells using ChatGPT: Initial Insights",
    "year": 2024,
    "venue": "ESEM '24",
    "strategies": [
      "Generic Prompt: Ask ChatGPT in open and generic terms to identify code smells without specifying which smells.",
      "Detailed Prompt: Explicitly list the target smells (Blob, Data Class, Feature Envy, Long Method) in the prompt to guide the model."
    ]
  },
  {
    "title": "Effective Vulnerable Function Identification based on CVE Description Empowered by Large Language Models",
    "year": 2024,
    "venue": "ASE 2024",
    "strategies": [
      "Customized In-Context Learning: Manually designed prompt templates based on CVE description patterns to extract key vulnerability-related entities.",
      "Priority Matching: Use the extracted entities to prioritize code locations for vulnerable function localization."
    ]
  },
  {
    "title": "Enhancing Static Analysis for Practical Bug Detection: An LLM-Integrated Approach",
    "year": 2024,
    "venue": "OOPSLA 2024",
    "strategies": [
      "Progressive Prompting: Iterative multi-turn prompts where the model requests additional code details on demand (“tell me more information”) and analysis continues progressively.",
      "Task Decomposition: Divide the overall analysis into separate conversations (initializer extraction, behavior summarization) to manage complexity.",
      "Self-Validation: After initial responses, prompt LLM to review and correct its own answers based on explicit rules.",
      "Chain-of-Thought & Structured Output: First elicit natural language reasoning, then prompt conversion into a structured JSON summary."
    ]
  },
  {
    "title": "Exploring ChatGPT’s Capabilities on Vulnerability Management",
    "year": 2024,
    "venue": "USENIX Security 2024",
    "strategies": [
      "Heuristic-Driven Template Design: Manually craft and refine prompt templates based on heuristics from prior work, evaluating them on probe-test subsets.",
      "Self-Heuristic Prompting: In prompts, ask ChatGPT to extract general principles from examples and apply those as expert rules, rather than just inserting raw demonstrations.",
      "Focus Guidance: Instruct the model to prioritize relevant information and ignore distractors in the prompt."
    ]
  },
  {
    "title": "Exploring the Influence of Prompts in LLMs for Security-Related Tasks",
    "year": 2024,
    "venue": "AISCC 2024 Workshop",
    "strategies": [
      "Prompt Structure vs. Content Analysis: Systematic evaluation of seven prompt structures (0-shot, 1-shot, few-shot variants) and nine content variants to identify optimal combinations.",
      "Prompt Decomposition: Break each prompt into 'structure' (format/pattern) and 'content' (wording) elements to isolate their effects.",
      "Performance-Guided Selection: Choose the best-performing prompt combinations for each security task."
    ]
  },
  {
    "title": "GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis",
    "year": 2024,
    "venue": "ICSE 2024",
    "strategies": [
      "System-Role Priming: 'You are a smart-contract auditor; identify logic flaws.'",
      "Scenario-Driven Templates: Bug-type-specific prompt templates describing code scenarios.",
      "Mimic-in-the-Background Self-Consistency: Internally answer multiple times and return the most frequent verdict.",
      "Two-Stage Chain-of-Thought: First extract key variables/statements, then statically confirm with analysis."
    ]
  },
  {
    "title": "Interleaving Static Analysis and LLM Prompting",
    "year": 2024,
    "venue": "SOAP 2024 Workshop",
    "strategies": [
      "Interleaved Pipeline: Alternate between static analysis results and LLM queries, using intermediate findings to construct the next prompt.",
      "Context-Aware Prompts: Include partial analysis outputs (e.g., function specs) in prompts to infer missing information via the LLM.",
      "Self-Consistency: Use few-shot and chain-of-thought examples to validate and reinforce inferred error specifications."
    ]
  },
  {
    "title": "LLMDFA: Analyzing Dataflow in Code with Large Language Models",
    "year": 2024,
    "venue": "NeurIPS 2024",
    "strategies": [
      "Task Decomposition: Split dataflow analysis into source/sink extraction, dataflow summarization, and path feasibility validation prompts.",
      "Code-Synthesis Delegation: Prompt the LLM to generate helper Python/SMT scripts for parsing and constraint solving, outsourcing delicate reasoning.",
      "Few-Shot Chain-of-Thought: Provide annotated examples and ask the model to think step-by-step through dataflow facts to reduce hallucinations."
    ]
  },
  {
    "title": "LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities (Yet?)",
    "year": 2024,
    "venue": "IEEE S&P 2024",
    "strategies": [
      "Zero-Shot System Prompts: Directly ask if code contains vulnerabilities, optionally listing CWE categories.",
      "Few-Shot and Chain-of-Thought Variants: Evaluate impact of adding examples and multi-step reasoning prompts over a benchmark.",
      "Prompt Robustness Testing: Perturb code and prompt phrasing to measure sensitivity and non-determinism of model outputs."
    ]
  },
  {
    "title": "Multi-Role Consensus through LLMs Discussions for Vulnerability Detection",
    "year": 2024,
    "venue": "arXiv Preprint",
    "strategies": [
      "Role-Playing Prompts: Assign multiple LLM agents distinct roles (tester, developer) with tailored system prompts.",
      "Dialectical Chain-of-Thought: Use iterative Q&A loops between roles to refine judgments through ‘pose query–respond–relay’ rounds.",
      "Consensus Prompting: Structure the interaction into initialization, discussion, and conclusion stages to reach a collective verdict."
    ]
  },
  {
    "title": "Prompt-Enhanced Software Vulnerability Detection Using ChatGPT",
    "year": 2024,
    "venue": "ACM Conference 2024",
    "strategies": [
      "Basic vs. Role-Based Prompts: Compare simple queries (‘Is this code buggy?’) with role instructions (‘Act as a vulnerability detector’).",
      "Auxiliary Info Integration: Embed structural (API call sequences) and sequential (data-flow) information into prompt templates (Pr-a-b, Pr-b-d).",
      "Multi-Round Chain-of-Thought: Two-step prompting (P(chain)1: code intent, P(chain)2: vulnerability assessment) leveraging dialogue memory.",
      "Position and Composition Tuning: Experiment with order of information blocks in the prompt to optimize detection accuracy."
    ]
  },
  {
    "title": "Prompt-Enhanced Software Vulnerability Detection Using ChatGPT",
    "year": 2024,
    "venue": "ICSE Workshop",
    "strategies": [
      "Enhanced Basic Prompts: Structural and sequential auxiliary information integrated into prompts.",
      "Multi-Round Dialogue Memory Prompts: Leverage ChatGPT's conversational memory for iterative refinement."
    ]
  },
  {
    "title": "Sanitizing Large Language Models in Bug Detection with Data-Flow",
    "year": 2024,
    "venue": "EMNLP Findings 2024",
    "strategies": [
      "Few-Shot Chain-of-Thought with Data-Flow Paths: Instruct LLM to emit detailed data-flow paths as proof.",
      "Sanitization Validators: Decompose paths into atomic checks (Data, Flow, Order, Reachability) to filter hallucinations."
    ]
  },
  {
    "title": "SkipAnalyzer: A Tool for Static Code Analysis with Large Language Models",
    "year": 2024,
    "venue": "arXiv preprint",
    "strategies": [
      "Zero-Shot / One-Shot / Few-Shot in Detector & Filter: K=3 examples for detection and filtering; one-shot includes a single example.",
      "Zero-Shot Only for Repair: Patch generator uses zero-shot prompts like 'Suggest a fix for this bug.'",
      "Zero-Shot Chain-of-Thought: Requests explanation of decision-making steps.",
      "Context Constraints: Limit inputs to single methods to fit within token limits."
    ]
  },
  {
    "title": "To Err Is Machine: Vulnerability Detection Challenges LLM Reasoning",
    "year": 2025,
    "venue": "Preprint",
    "strategies": [
      "Basic Zero-Shot Prompting: System prompt + 'Is the following function buggy? Yes or No.' variants with CWE listing.",
      "In-Context N-Shot Prompting: Provide 1 examples, using random sampling, retrieval-augmented, and contrastive pairs.",
      "Contrastive-Pair Prompting: Before/after code snippets highlighting fine-grained differences.",
      "Chain-of-Thought from CVE Descriptions: Use natural-language CVE reports as multi-step reasoning examples.",
      "Chain-of-Thought from Static Analysis: Convert static analyzer paths into step-by-step reasoning."
    ]
  }
]
